/// Parse the output from the detection model and return a list of bounding boxes
///
/// This method handles all data post-processing
///
/// - Parameter outputTensor: The output tensor after invoking with input
/// - Returns: list of bounding boxes stored in Prediction data type
private func parseDetectionModelOutput(from outputTensor: Tensor) -> [BoundingBox] {

    // Convert the bytes from the output tensor to a list of Float32
    let outputSize = outputTensor.shape.dimensions.reduce(1, {x, y in x * y})
    let outputData = UnsafeMutableBufferPointer<Float32>.allocate(capacity: outputSize)
    var _ = outputTensor.data.copyBytes(to: outputData)

    var detections: [BoundingBox] = []

    // 6x1344 dimensional output (6 rows of size 1344)
    // Output describes bounding box location, dimension and confidence score
    // Note that bounding box information is relative to resized input image
    for i in (0..<1344) {
        // Keep as Float32 to avoid overflow, then convert safely
        let xm_float = outputData[i]  // 0th row is x-middle
        let ym_float = outputData[i + 1344] // 1st row is y-middle
        let w_float = outputData[i + 1344 * 2] // width
        let h_float = outputData[i + 1344 * 3]   // height
        let conf = outputData[i + 1344 * 5] // confidence of detection

        // Only keep detections with high confidence scores
        if conf > detectionConfidenceThreshold {
            // Safely convert to CGFloat for CGRect (which can handle larger values)
            let xm = CGFloat(xm_float)
            let ym = CGFloat(ym_float)
            let w = CGFloat(w_float)
            let h = CGFloat(h_float)
            
            // Assign ID so we can map embeddings -> Bounding Boxes
            let bounding_box = BoundingBox(
                rect: CGRect(x: xm, y: ym, width: w, height: h), 
                conf: conf, 
                id: detections.count + 1
            )
            detections.append(bounding_box)
        }
    }

    return detections
}
